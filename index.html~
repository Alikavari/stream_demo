<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>AssemblyAI Realtime â€” HTML + JS Fixed</title>
  <style>
    body { font-family: system-ui, sans-serif; margin:0; background:#f6f7f9; color:#222; }
    .wrap { max-width:800px; margin:40px auto; background:#fff; padding:24px; border-radius:12px; box-shadow:0 4px 18px rgba(0,0,0,.08);}
    button{padding:10px 16px;border:0;border-radius:8px;background:#42b883;color:#fff;cursor:pointer}
    button:hover{background:#2e8b63}
    .log{background:#0f172a;color:#e2e8f0;font-family:monospace;padding:10px;border-radius:8px;height:160px;overflow:auto;margin-top:8px}
    .transcript{background:#f1f5f9;border-radius:8px;padding:12px;min-height:120px;margin-top:8px;white-space:pre-wrap}
  </style>
</head>
<body>
  <div class="wrap">
    <h2>ðŸŽ¤ AssemblyAI Realtime (Fixed)</h2>
    <button id="btn">Start Recording</button>
    <span id="status">Idle</span>
    <div id="transcript" class="transcript"></div>
    <div id="log" class="log"></div>
  </div>

<script>
const TOKEN_URL = "http://localhost:8000/get_token";
const SAMPLE_RATE = 16000;
const CHUNK_MS = 100;

const $btn=document.getElementById("btn");
const $status=document.getElementById("status");
const $log=document.getElementById("log");
const $out=document.getElementById("transcript");
const log=(...a)=>{$log.textContent+=a.join(" ")+"\n";$log.scrollTop=$log.scrollHeight;}

let ws=null,audioContext=null,mediaStream=null,workletNode=null,isRec=false;

// Create the worklet JS as a blob *inside* start(), after user click
const makeWorkletBlob = () => {
  const code = `
    function downsampleTo16k(float32, inputRate){
      const target=16000; if(inputRate===target) return float32;
      const ratio=inputRate/target, newLen=Math.floor(float32.length/ratio);
      const res=new Float32Array(newLen);
      for(let i=0;i<newLen;i++){
        const start=Math.floor(i*ratio), end=Math.floor((i+1)*ratio);
        let sum=0; for(let j=start;j<end&&j<float32.length;j++) sum+=float32[j];
        res[i]=sum/Math.max(1,end-start);
      }
      return res;
    }
    class PCM16Downsampler extends AudioWorkletProcessor{
      constructor(){super();this.inputRate=sampleRate;this.buf=new Float32Array(0);this.samplesPer=1600;}
      append(x){const out=new Float32Array(this.buf.length+x.length);out.set(this.buf);out.set(x,this.buf.length);this.buf=out;}
      take(n){const c=this.buf.slice(0,n);this.buf=this.buf.slice(n);return c;}
      f32toI16(f32){const i16=new Int16Array(f32.length);
        for(let i=0;i<f32.length;i++){const s=Math.max(-1,Math.min(1,f32[i]));i16[i]=s<0?s*0x8000:s*0x7fff;}return i16;}
      process(inputs){const input=inputs[0];if(!input||!input[0])return true;
        const mono=input[0], f16=downsampleTo16k(mono,this.inputRate);this.append(f16);
        while(this.buf.length>=this.samplesPer){const b=this.take(this.samplesPer);const i16=this.f32toI16(b);
          this.port.postMessage(i16.buffer,[i16.buffer]);}
        return true;}
    }
    registerProcessor("pcm16-downsampler",PCM16Downsampler);
  `;
  return URL.createObjectURL(new Blob([code],{type:"application/javascript"}));
};

async function start(){
  try{
    $btn.disabled=true;$status.textContent="Requesting micâ€¦";
    mediaStream=await navigator.mediaDevices.getUserMedia({audio:true});

    $status.textContent="Getting tokenâ€¦";
    const t=await fetch(TOKEN_URL).then(r=>r.json());
    if(!t.token) throw new Error(t.error||"No token");
    const token=t.token;

    $status.textContent="Connecting WSâ€¦";
    ws=new WebSocket(`wss://streaming.assemblyai.com/v3/ws?sample_rate=${SAMPLE_RATE}&token=${encodeURIComponent(token)}`);
    ws.onopen=async()=>{
      log("âœ… WS open");
      $status.textContent="Streamingâ€¦";

      // now safe to create AudioContext + worklet
      audioContext=new AudioContext({sampleRate:SAMPLE_RATE});
      const blobURL=makeWorkletBlob();
      await audioContext.audioWorklet.addModule(blobURL);
      URL.revokeObjectURL(blobURL);

      const src=audioContext.createMediaStreamSource(mediaStream);
      workletNode=new AudioWorkletNode(audioContext,"pcm16-downsampler");
      workletNode.port.onmessage=(e)=>{
        if(ws&&ws.readyState===WebSocket.OPEN){ws.send(e.data);}
      };
      const silent=audioContext.createGain();silent.gain.value=0;
      src.connect(workletNode).connect(silent).connect(audioContext.destination);

      
    let partial = "";
    let fullTranscript = "";

    ws.onmessage = (evt) => {
    try {
        const msg = JSON.parse(evt.data);

        // v3 sends everything as type "Turn"
        if (msg.type === "Turn" && msg.transcript) {
        // still speaking â†’ show as partial
        if (!msg.end_of_turn) {
            partial = msg.transcript.trim();
        }
        // pause detected â†’ finalize
        else if (msg.end_of_turn) {
            const text = msg.transcript.trim();
            if (text) fullTranscript += text + " ";
            partial = "";
        }
        }

    // display combined
    $out.textContent = fullTranscript + (partial ? "â–Œ" + partial : "");

    if (msg.type === "Begin") log("Session", msg.id);
  } catch (e) {
    console.warn("Bad JSON:", evt.data);
  }
};

    
      ws.onclose=(e)=>{log("ðŸ”´ WS closed",e.code,e.reason);stop();};
      ws.onerror=(e)=>{console.error(e);};

      isRec=true;$btn.textContent="Stop Recording";$btn.disabled=false;
    };
  }catch(e){console.error(e);$status.textContent="Error";log("ERR",e);}
}

function stop(){
  isRec=false;$btn.textContent="Start Recording";
  if(workletNode)try{workletNode.disconnect();}catch{}
  if(audioContext)try{audioContext.close();}catch{}
  if(mediaStream)try{mediaStream.getTracks().forEach(t=>t.stop());}catch{}
  if(ws)try{ws.close();}catch{}
  $status.textContent="Stopped";
}

$btn.onclick=()=>isRec?stop():start();
window.onbeforeunload=stop;
</script>
</body>
</html>
